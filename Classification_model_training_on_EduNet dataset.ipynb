{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2fa1fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f252a16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV data into a DataFrame\n",
    "data = pd.read_csv('consolidated_muitimodel_features_L1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b994dee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BF1</th>\n",
       "      <th>BF2</th>\n",
       "      <th>BF3</th>\n",
       "      <th>BF4</th>\n",
       "      <th>BF5</th>\n",
       "      <th>BF6</th>\n",
       "      <th>BF7</th>\n",
       "      <th>BF8</th>\n",
       "      <th>BF9</th>\n",
       "      <th>BF10</th>\n",
       "      <th>...</th>\n",
       "      <th>FF15</th>\n",
       "      <th>FF16</th>\n",
       "      <th>FF17</th>\n",
       "      <th>FF18</th>\n",
       "      <th>FF19</th>\n",
       "      <th>FF20</th>\n",
       "      <th>FF21</th>\n",
       "      <th>FF22</th>\n",
       "      <th>FF23</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.520532</td>\n",
       "      <td>0.371067</td>\n",
       "      <td>0.472170</td>\n",
       "      <td>0.390838</td>\n",
       "      <td>0.292039</td>\n",
       "      <td>0.413435</td>\n",
       "      <td>0.044622</td>\n",
       "      <td>0.678943</td>\n",
       "      <td>1.000001</td>\n",
       "      <td>1.000001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.434624</td>\n",
       "      <td>0.343060</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.118475</td>\n",
       "      <td>0.985221</td>\n",
       "      <td>1.335959e-06</td>\n",
       "      <td>-70.141103</td>\n",
       "      <td>-1.304535</td>\n",
       "      <td>-7.499232</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.266229</td>\n",
       "      <td>0.373001</td>\n",
       "      <td>0.066236</td>\n",
       "      <td>0.764186</td>\n",
       "      <td>0.290696</td>\n",
       "      <td>0.894581</td>\n",
       "      <td>...</td>\n",
       "      <td>0.823287</td>\n",
       "      <td>0.624990</td>\n",
       "      <td>0.248707</td>\n",
       "      <td>0.804156</td>\n",
       "      <td>0.830855</td>\n",
       "      <td>4.838982e-08</td>\n",
       "      <td>-34.938633</td>\n",
       "      <td>55.350706</td>\n",
       "      <td>12.182323</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.533891</td>\n",
       "      <td>0.461944</td>\n",
       "      <td>0.478577</td>\n",
       "      <td>0.489047</td>\n",
       "      <td>0.290990</td>\n",
       "      <td>0.409997</td>\n",
       "      <td>0.028048</td>\n",
       "      <td>0.649405</td>\n",
       "      <td>0.196395</td>\n",
       "      <td>0.754428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.122684</td>\n",
       "      <td>0.718189</td>\n",
       "      <td>0.006283</td>\n",
       "      <td>0.011310</td>\n",
       "      <td>0.448108</td>\n",
       "      <td>4.034231e-05</td>\n",
       "      <td>-33.387659</td>\n",
       "      <td>13.838012</td>\n",
       "      <td>20.289297</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.551083</td>\n",
       "      <td>0.479474</td>\n",
       "      <td>0.493723</td>\n",
       "      <td>0.503577</td>\n",
       "      <td>0.301975</td>\n",
       "      <td>0.356861</td>\n",
       "      <td>0.052868</td>\n",
       "      <td>0.602087</td>\n",
       "      <td>0.225768</td>\n",
       "      <td>0.724701</td>\n",
       "      <td>...</td>\n",
       "      <td>0.529281</td>\n",
       "      <td>0.146233</td>\n",
       "      <td>0.027507</td>\n",
       "      <td>0.653014</td>\n",
       "      <td>0.994324</td>\n",
       "      <td>1.873196e-03</td>\n",
       "      <td>-32.512312</td>\n",
       "      <td>29.600823</td>\n",
       "      <td>4.233699</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.509558</td>\n",
       "      <td>0.387582</td>\n",
       "      <td>0.485777</td>\n",
       "      <td>0.387582</td>\n",
       "      <td>0.277698</td>\n",
       "      <td>0.488554</td>\n",
       "      <td>0.044848</td>\n",
       "      <td>0.755917</td>\n",
       "      <td>0.300488</td>\n",
       "      <td>0.821335</td>\n",
       "      <td>...</td>\n",
       "      <td>0.165180</td>\n",
       "      <td>0.235198</td>\n",
       "      <td>0.002606</td>\n",
       "      <td>0.022278</td>\n",
       "      <td>0.658321</td>\n",
       "      <td>1.277089e-06</td>\n",
       "      <td>-49.380323</td>\n",
       "      <td>-19.922609</td>\n",
       "      <td>-22.094104</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 94 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        BF1       BF2       BF3       BF4       BF5       BF6       BF7  \\\n",
       "0  0.520532  0.371067  0.472170  0.390838  0.292039  0.413435  0.044622   \n",
       "1  0.000001  0.000001  0.000001  0.000001  0.266229  0.373001  0.066236   \n",
       "2  0.533891  0.461944  0.478577  0.489047  0.290990  0.409997  0.028048   \n",
       "3  0.551083  0.479474  0.493723  0.503577  0.301975  0.356861  0.052868   \n",
       "4  0.509558  0.387582  0.485777  0.387582  0.277698  0.488554  0.044848   \n",
       "\n",
       "        BF8       BF9      BF10  ...      FF15      FF16      FF17      FF18  \\\n",
       "0  0.678943  1.000001  1.000001  ...  0.434624  0.343060  0.000065  0.118475   \n",
       "1  0.764186  0.290696  0.894581  ...  0.823287  0.624990  0.248707  0.804156   \n",
       "2  0.649405  0.196395  0.754428  ...  0.122684  0.718189  0.006283  0.011310   \n",
       "3  0.602087  0.225768  0.724701  ...  0.529281  0.146233  0.027507  0.653014   \n",
       "4  0.755917  0.300488  0.821335  ...  0.165180  0.235198  0.002606  0.022278   \n",
       "\n",
       "       FF19          FF20       FF21       FF22       FF23  label  \n",
       "0  0.985221  1.335959e-06 -70.141103  -1.304535  -7.499232      0  \n",
       "1  0.830855  4.838982e-08 -34.938633  55.350706  12.182323      0  \n",
       "2  0.448108  4.034231e-05 -33.387659  13.838012  20.289297      0  \n",
       "3  0.994324  1.873196e-03 -32.512312  29.600823   4.233699      0  \n",
       "4  0.658321  1.277089e-06 -49.380323 -19.922609 -22.094104      0  \n",
       "\n",
       "[5 rows x 94 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49be529d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = data.sample(frac = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69ec1cc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BF1</th>\n",
       "      <th>BF2</th>\n",
       "      <th>BF3</th>\n",
       "      <th>BF4</th>\n",
       "      <th>BF5</th>\n",
       "      <th>BF6</th>\n",
       "      <th>BF7</th>\n",
       "      <th>BF8</th>\n",
       "      <th>BF9</th>\n",
       "      <th>BF10</th>\n",
       "      <th>...</th>\n",
       "      <th>FF15</th>\n",
       "      <th>FF16</th>\n",
       "      <th>FF17</th>\n",
       "      <th>FF18</th>\n",
       "      <th>FF19</th>\n",
       "      <th>FF20</th>\n",
       "      <th>FF21</th>\n",
       "      <th>FF22</th>\n",
       "      <th>FF23</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6795</th>\n",
       "      <td>0.408186</td>\n",
       "      <td>0.625272</td>\n",
       "      <td>0.378068</td>\n",
       "      <td>0.826117</td>\n",
       "      <td>0.143401</td>\n",
       "      <td>0.847804</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.000001</td>\n",
       "      <td>1.000001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.603972</td>\n",
       "      <td>0.176415</td>\n",
       "      <td>0.898586</td>\n",
       "      <td>0.768563</td>\n",
       "      <td>0.249128</td>\n",
       "      <td>4.240656e-07</td>\n",
       "      <td>0.937000</td>\n",
       "      <td>1.434036</td>\n",
       "      <td>-6.516444</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9420</th>\n",
       "      <td>0.535168</td>\n",
       "      <td>0.385598</td>\n",
       "      <td>0.484187</td>\n",
       "      <td>0.597466</td>\n",
       "      <td>0.135819</td>\n",
       "      <td>0.598979</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.000001</td>\n",
       "      <td>1.000001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.830610</td>\n",
       "      <td>0.333492</td>\n",
       "      <td>0.982110</td>\n",
       "      <td>0.555154</td>\n",
       "      <td>0.007616</td>\n",
       "      <td>2.437719e-03</td>\n",
       "      <td>-1.185154</td>\n",
       "      <td>11.641846</td>\n",
       "      <td>30.464378</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9290</th>\n",
       "      <td>0.425450</td>\n",
       "      <td>0.377344</td>\n",
       "      <td>0.517043</td>\n",
       "      <td>0.603287</td>\n",
       "      <td>0.138459</td>\n",
       "      <td>0.601673</td>\n",
       "      <td>0.232087</td>\n",
       "      <td>1.019668</td>\n",
       "      <td>0.280937</td>\n",
       "      <td>0.754992</td>\n",
       "      <td>...</td>\n",
       "      <td>0.564124</td>\n",
       "      <td>0.678262</td>\n",
       "      <td>0.386535</td>\n",
       "      <td>0.482697</td>\n",
       "      <td>0.254137</td>\n",
       "      <td>2.527707e-07</td>\n",
       "      <td>-7.491005</td>\n",
       "      <td>-0.715313</td>\n",
       "      <td>0.923619</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8151</th>\n",
       "      <td>0.369676</td>\n",
       "      <td>0.592326</td>\n",
       "      <td>0.496755</td>\n",
       "      <td>0.666755</td>\n",
       "      <td>0.281273</td>\n",
       "      <td>0.738084</td>\n",
       "      <td>0.067633</td>\n",
       "      <td>0.907617</td>\n",
       "      <td>0.412035</td>\n",
       "      <td>0.933461</td>\n",
       "      <td>...</td>\n",
       "      <td>0.349073</td>\n",
       "      <td>0.174871</td>\n",
       "      <td>0.230579</td>\n",
       "      <td>0.461218</td>\n",
       "      <td>0.752910</td>\n",
       "      <td>2.842648e-08</td>\n",
       "      <td>3.178285</td>\n",
       "      <td>5.326247</td>\n",
       "      <td>-7.268564</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5011</th>\n",
       "      <td>0.529510</td>\n",
       "      <td>0.332330</td>\n",
       "      <td>0.472060</td>\n",
       "      <td>0.470951</td>\n",
       "      <td>0.179819</td>\n",
       "      <td>0.469975</td>\n",
       "      <td>0.062422</td>\n",
       "      <td>0.837030</td>\n",
       "      <td>0.297215</td>\n",
       "      <td>0.767719</td>\n",
       "      <td>...</td>\n",
       "      <td>0.659805</td>\n",
       "      <td>0.186817</td>\n",
       "      <td>0.001428</td>\n",
       "      <td>0.084600</td>\n",
       "      <td>0.992329</td>\n",
       "      <td>2.184283e-08</td>\n",
       "      <td>-54.986918</td>\n",
       "      <td>-14.421248</td>\n",
       "      <td>0.309627</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 94 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           BF1       BF2       BF3       BF4       BF5       BF6       BF7  \\\n",
       "6795  0.408186  0.625272  0.378068  0.826117  0.143401  0.847804  0.000001   \n",
       "9420  0.535168  0.385598  0.484187  0.597466  0.135819  0.598979  0.000001   \n",
       "9290  0.425450  0.377344  0.517043  0.603287  0.138459  0.601673  0.232087   \n",
       "8151  0.369676  0.592326  0.496755  0.666755  0.281273  0.738084  0.067633   \n",
       "5011  0.529510  0.332330  0.472060  0.470951  0.179819  0.469975  0.062422   \n",
       "\n",
       "           BF8       BF9      BF10  ...      FF15      FF16      FF17  \\\n",
       "6795  0.000001  1.000001  1.000001  ...  0.603972  0.176415  0.898586   \n",
       "9420  0.000001  1.000001  1.000001  ...  0.830610  0.333492  0.982110   \n",
       "9290  1.019668  0.280937  0.754992  ...  0.564124  0.678262  0.386535   \n",
       "8151  0.907617  0.412035  0.933461  ...  0.349073  0.174871  0.230579   \n",
       "5011  0.837030  0.297215  0.767719  ...  0.659805  0.186817  0.001428   \n",
       "\n",
       "          FF18      FF19          FF20       FF21       FF22       FF23  label  \n",
       "6795  0.768563  0.249128  4.240656e-07   0.937000   1.434036  -6.516444      3  \n",
       "9420  0.555154  0.007616  2.437719e-03  -1.185154  11.641846  30.464378      4  \n",
       "9290  0.482697  0.254137  2.527707e-07  -7.491005  -0.715313   0.923619      4  \n",
       "8151  0.461218  0.752910  2.842648e-08   3.178285   5.326247  -7.268564      3  \n",
       "5011  0.084600  0.992329  2.184283e-08 -54.986918 -14.421248   0.309627      2  \n",
       "\n",
       "[5 rows x 94 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff663c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features (X) and labels (y)\n",
    "X = data1.iloc[:, :-1]  # Assuming the features are in the first columns\n",
    "y = data1.iloc[:, -1]   # Assuming the labels are in the last column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "559572ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11568, 93)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5df94bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11568,)\n"
     ]
    }
   ],
   "source": [
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64ec9e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply label encoding to convert class labels to numerical values\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd8fc733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 4, 4, ..., 3, 0, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7457b999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply one-hot encoding to create binary columns for each class\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "y_onehot = onehot_encoder.fit_transform(y_encoded.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e51e4342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (11568, 93)\n",
      "Encoded labels shape: (11568,)\n",
      "One-hot encoded labels shape: (11568, 5)\n"
     ]
    }
   ],
   "source": [
    "# Print the shapes of the preprocessed data\n",
    "print(\"Features shape:\", X.shape)\n",
    "print(\"Encoded labels shape:\", y_encoded.shape)\n",
    "print(\"One-hot encoded labels shape:\", y_onehot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38530cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_onehot, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3c40061",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import kurtosis\n",
    "from scipy.stats import skew\n",
    "import seaborn as sn\n",
    "import os\n",
    "#from keras.models import Sequential\n",
    "#from keras.layers import Dense\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad9d38fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-18 04:41:32.585690: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-18 04:41:32.592454: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-18 04:41:32.593174: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-18 04:41:32.594384: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-18 04:41:32.595084: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-18 04:41:32.595609: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-18 04:41:32.596115: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-18 04:41:32.878868: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-18 04:41:32.879312: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-18 04:41:32.879712: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-18 04:41:32.880087: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14584 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:2d:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# Define the neural network architecture\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(256, input_shape=(X_train.shape[1],), activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(64,activation='relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(y_onehot.shape[1], activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ade36fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8419501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 256)               24064     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 256)              1024      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 5)                 165       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 68,997\n",
      "Trainable params: 68,229\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e907429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      " 62/463 [===>..........................] - ETA: 1s - loss: 1.4209 - accuracy: 0.3972"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-18 04:41:36.634681: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "463/463 [==============================] - 2s 3ms/step - loss: 1.0521 - accuracy: 0.5977 - val_loss: 0.6614 - val_accuracy: 0.7553\n",
      "Epoch 2/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.6494 - accuracy: 0.7623 - val_loss: 0.3556 - val_accuracy: 0.8698\n",
      "Epoch 3/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.5602 - accuracy: 0.8014 - val_loss: 0.3126 - val_accuracy: 0.8957\n",
      "Epoch 4/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.4686 - accuracy: 0.8295 - val_loss: 0.2416 - val_accuracy: 0.9173\n",
      "Epoch 5/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.4243 - accuracy: 0.8499 - val_loss: 0.2471 - val_accuracy: 0.9125\n",
      "Epoch 6/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.4021 - accuracy: 0.8586 - val_loss: 0.2209 - val_accuracy: 0.9238\n",
      "Epoch 7/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.3941 - accuracy: 0.8582 - val_loss: 0.2242 - val_accuracy: 0.9233\n",
      "Epoch 8/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.3701 - accuracy: 0.8698 - val_loss: 0.1975 - val_accuracy: 0.9319\n",
      "Epoch 9/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.3533 - accuracy: 0.8771 - val_loss: 0.1820 - val_accuracy: 0.9368\n",
      "Epoch 10/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.3285 - accuracy: 0.8840 - val_loss: 0.2475 - val_accuracy: 0.9087\n",
      "Epoch 11/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.3236 - accuracy: 0.8856 - val_loss: 0.1745 - val_accuracy: 0.9341\n",
      "Epoch 12/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.3242 - accuracy: 0.8860 - val_loss: 0.1729 - val_accuracy: 0.9379\n",
      "Epoch 13/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.3170 - accuracy: 0.8941 - val_loss: 0.1714 - val_accuracy: 0.9384\n",
      "Epoch 14/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.3115 - accuracy: 0.8896 - val_loss: 0.1645 - val_accuracy: 0.9411\n",
      "Epoch 15/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.2978 - accuracy: 0.8960 - val_loss: 0.1707 - val_accuracy: 0.9400\n",
      "Epoch 16/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.2881 - accuracy: 0.9026 - val_loss: 0.1533 - val_accuracy: 0.9422\n",
      "Epoch 17/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.2869 - accuracy: 0.9003 - val_loss: 0.1355 - val_accuracy: 0.9530\n",
      "Epoch 18/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.2819 - accuracy: 0.9019 - val_loss: 0.1753 - val_accuracy: 0.9330\n",
      "Epoch 19/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.2716 - accuracy: 0.9086 - val_loss: 0.1732 - val_accuracy: 0.9330\n",
      "Epoch 20/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.2843 - accuracy: 0.9015 - val_loss: 0.2105 - val_accuracy: 0.9238\n",
      "Epoch 21/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.2652 - accuracy: 0.9092 - val_loss: 0.1363 - val_accuracy: 0.9546\n",
      "Epoch 22/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.2677 - accuracy: 0.9068 - val_loss: 0.1941 - val_accuracy: 0.9335\n",
      "Epoch 23/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.2797 - accuracy: 0.9057 - val_loss: 0.1527 - val_accuracy: 0.9427\n",
      "Epoch 24/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.2700 - accuracy: 0.9096 - val_loss: 0.1554 - val_accuracy: 0.9471\n",
      "Epoch 25/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.2531 - accuracy: 0.9115 - val_loss: 0.1395 - val_accuracy: 0.9498\n",
      "Epoch 26/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.2505 - accuracy: 0.9121 - val_loss: 0.1272 - val_accuracy: 0.9568\n",
      "Epoch 27/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.2426 - accuracy: 0.9191 - val_loss: 0.1330 - val_accuracy: 0.9503\n",
      "Epoch 28/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.2501 - accuracy: 0.9173 - val_loss: 0.1290 - val_accuracy: 0.9519\n",
      "Epoch 29/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.2474 - accuracy: 0.9110 - val_loss: 0.1158 - val_accuracy: 0.9562\n",
      "Epoch 30/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.2387 - accuracy: 0.9183 - val_loss: 0.1045 - val_accuracy: 0.9692\n",
      "Epoch 31/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.2502 - accuracy: 0.9173 - val_loss: 0.1160 - val_accuracy: 0.9584\n",
      "Epoch 32/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.2364 - accuracy: 0.9194 - val_loss: 0.1314 - val_accuracy: 0.9557\n",
      "Epoch 33/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.2349 - accuracy: 0.9198 - val_loss: 0.1283 - val_accuracy: 0.9541\n",
      "Epoch 34/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.2350 - accuracy: 0.9202 - val_loss: 0.1253 - val_accuracy: 0.9541\n",
      "Epoch 35/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.2358 - accuracy: 0.9184 - val_loss: 0.1127 - val_accuracy: 0.9606\n",
      "Epoch 36/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.2414 - accuracy: 0.9188 - val_loss: 0.1483 - val_accuracy: 0.9449\n",
      "Epoch 37/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.2231 - accuracy: 0.9239 - val_loss: 0.1122 - val_accuracy: 0.9643\n",
      "Epoch 38/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.2322 - accuracy: 0.9192 - val_loss: 0.1031 - val_accuracy: 0.9638\n",
      "Epoch 39/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.2075 - accuracy: 0.9256 - val_loss: 0.0987 - val_accuracy: 0.9654\n",
      "Epoch 40/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.2190 - accuracy: 0.9230 - val_loss: 0.0984 - val_accuracy: 0.9665\n",
      "Epoch 41/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.2218 - accuracy: 0.9208 - val_loss: 0.1124 - val_accuracy: 0.9589\n",
      "Epoch 42/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.2089 - accuracy: 0.9294 - val_loss: 0.0999 - val_accuracy: 0.9687\n",
      "Epoch 43/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.2084 - accuracy: 0.9295 - val_loss: 0.1073 - val_accuracy: 0.9660\n",
      "Epoch 44/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.2187 - accuracy: 0.9248 - val_loss: 0.1006 - val_accuracy: 0.9638\n",
      "Epoch 45/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.2008 - accuracy: 0.9300 - val_loss: 0.1131 - val_accuracy: 0.9622\n",
      "Epoch 46/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.2184 - accuracy: 0.9279 - val_loss: 0.1137 - val_accuracy: 0.9665\n",
      "Epoch 47/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.2184 - accuracy: 0.9244 - val_loss: 0.1158 - val_accuracy: 0.9622\n",
      "Epoch 48/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.2100 - accuracy: 0.9258 - val_loss: 0.0986 - val_accuracy: 0.9660\n",
      "Epoch 49/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.2122 - accuracy: 0.9272 - val_loss: 0.0935 - val_accuracy: 0.9697\n",
      "Epoch 50/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.2038 - accuracy: 0.9323 - val_loss: 0.1209 - val_accuracy: 0.9573\n",
      "Epoch 51/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1984 - accuracy: 0.9280 - val_loss: 0.1212 - val_accuracy: 0.9622\n",
      "Epoch 52/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.2109 - accuracy: 0.9285 - val_loss: 0.0874 - val_accuracy: 0.9730\n",
      "Epoch 53/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.2008 - accuracy: 0.9292 - val_loss: 0.1151 - val_accuracy: 0.9606\n",
      "Epoch 54/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.2028 - accuracy: 0.9325 - val_loss: 0.1004 - val_accuracy: 0.9627\n",
      "Epoch 55/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1948 - accuracy: 0.9356 - val_loss: 0.0961 - val_accuracy: 0.9670\n",
      "Epoch 56/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1837 - accuracy: 0.9395 - val_loss: 0.0904 - val_accuracy: 0.9687\n",
      "Epoch 57/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1907 - accuracy: 0.9371 - val_loss: 0.1134 - val_accuracy: 0.9606\n",
      "Epoch 58/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "463/463 [==============================] - 1s 3ms/step - loss: 0.2055 - accuracy: 0.9329 - val_loss: 0.0847 - val_accuracy: 0.9719\n",
      "Epoch 59/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1881 - accuracy: 0.9366 - val_loss: 0.0897 - val_accuracy: 0.9687\n",
      "Epoch 60/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1971 - accuracy: 0.9331 - val_loss: 0.1003 - val_accuracy: 0.9643\n",
      "Epoch 61/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.2013 - accuracy: 0.9279 - val_loss: 0.0822 - val_accuracy: 0.9762\n",
      "Epoch 62/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.2058 - accuracy: 0.9299 - val_loss: 0.0799 - val_accuracy: 0.9719\n",
      "Epoch 63/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1974 - accuracy: 0.9344 - val_loss: 0.0847 - val_accuracy: 0.9708\n",
      "Epoch 64/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1961 - accuracy: 0.9322 - val_loss: 0.0752 - val_accuracy: 0.9746\n",
      "Epoch 65/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1875 - accuracy: 0.9356 - val_loss: 0.0783 - val_accuracy: 0.9719\n",
      "Epoch 66/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1799 - accuracy: 0.9369 - val_loss: 0.1010 - val_accuracy: 0.9643\n",
      "Epoch 67/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1820 - accuracy: 0.9393 - val_loss: 0.0781 - val_accuracy: 0.9741\n",
      "Epoch 68/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1949 - accuracy: 0.9346 - val_loss: 0.0847 - val_accuracy: 0.9751\n",
      "Epoch 69/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1709 - accuracy: 0.9385 - val_loss: 0.0846 - val_accuracy: 0.9778\n",
      "Epoch 70/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1830 - accuracy: 0.9377 - val_loss: 0.0822 - val_accuracy: 0.9751\n",
      "Epoch 71/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1844 - accuracy: 0.9387 - val_loss: 0.0766 - val_accuracy: 0.9724\n",
      "Epoch 72/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1763 - accuracy: 0.9384 - val_loss: 0.0784 - val_accuracy: 0.9730\n",
      "Epoch 73/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1765 - accuracy: 0.9384 - val_loss: 0.0780 - val_accuracy: 0.9741\n",
      "Epoch 74/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1848 - accuracy: 0.9377 - val_loss: 0.0720 - val_accuracy: 0.9789\n",
      "Epoch 75/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1696 - accuracy: 0.9410 - val_loss: 0.0751 - val_accuracy: 0.9762\n",
      "Epoch 76/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1845 - accuracy: 0.9346 - val_loss: 0.0877 - val_accuracy: 0.9708\n",
      "Epoch 77/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1804 - accuracy: 0.9339 - val_loss: 0.0885 - val_accuracy: 0.9703\n",
      "Epoch 78/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1736 - accuracy: 0.9402 - val_loss: 0.0807 - val_accuracy: 0.9741\n",
      "Epoch 79/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1795 - accuracy: 0.9361 - val_loss: 0.0891 - val_accuracy: 0.9697\n",
      "Epoch 80/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1843 - accuracy: 0.9352 - val_loss: 0.0825 - val_accuracy: 0.9724\n",
      "Epoch 81/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1905 - accuracy: 0.9341 - val_loss: 0.0934 - val_accuracy: 0.9665\n",
      "Epoch 82/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1695 - accuracy: 0.9419 - val_loss: 0.0783 - val_accuracy: 0.9773\n",
      "Epoch 83/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1703 - accuracy: 0.9402 - val_loss: 0.0881 - val_accuracy: 0.9703\n",
      "Epoch 84/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1689 - accuracy: 0.9431 - val_loss: 0.0871 - val_accuracy: 0.9735\n",
      "Epoch 85/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1737 - accuracy: 0.9411 - val_loss: 0.0792 - val_accuracy: 0.9724\n",
      "Epoch 86/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1648 - accuracy: 0.9404 - val_loss: 0.1022 - val_accuracy: 0.9665\n",
      "Epoch 87/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1755 - accuracy: 0.9377 - val_loss: 0.0794 - val_accuracy: 0.9768\n",
      "Epoch 88/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1680 - accuracy: 0.9425 - val_loss: 0.0736 - val_accuracy: 0.9778\n",
      "Epoch 89/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1720 - accuracy: 0.9411 - val_loss: 0.0822 - val_accuracy: 0.9719\n",
      "Epoch 90/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1727 - accuracy: 0.9403 - val_loss: 0.0831 - val_accuracy: 0.9703\n",
      "Epoch 91/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1716 - accuracy: 0.9398 - val_loss: 0.0777 - val_accuracy: 0.9746\n",
      "Epoch 92/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1632 - accuracy: 0.9429 - val_loss: 0.0843 - val_accuracy: 0.9741\n",
      "Epoch 93/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1661 - accuracy: 0.9398 - val_loss: 0.0996 - val_accuracy: 0.9670\n",
      "Epoch 94/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1619 - accuracy: 0.9456 - val_loss: 0.0859 - val_accuracy: 0.9741\n",
      "Epoch 95/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1666 - accuracy: 0.9427 - val_loss: 0.0734 - val_accuracy: 0.9800\n",
      "Epoch 96/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1626 - accuracy: 0.9448 - val_loss: 0.0992 - val_accuracy: 0.9692\n",
      "Epoch 97/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1735 - accuracy: 0.9396 - val_loss: 0.0696 - val_accuracy: 0.9795\n",
      "Epoch 98/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1629 - accuracy: 0.9439 - val_loss: 0.0892 - val_accuracy: 0.9719\n",
      "Epoch 99/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1733 - accuracy: 0.9385 - val_loss: 0.1135 - val_accuracy: 0.9573\n",
      "Epoch 100/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1720 - accuracy: 0.9407 - val_loss: 0.0899 - val_accuracy: 0.9660\n",
      "Epoch 101/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1654 - accuracy: 0.9461 - val_loss: 0.0864 - val_accuracy: 0.9735\n",
      "Epoch 102/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1557 - accuracy: 0.9470 - val_loss: 0.0846 - val_accuracy: 0.9708\n",
      "Epoch 103/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1548 - accuracy: 0.9485 - val_loss: 0.0858 - val_accuracy: 0.9724\n",
      "Epoch 104/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1632 - accuracy: 0.9437 - val_loss: 0.0749 - val_accuracy: 0.9784\n",
      "Epoch 105/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1518 - accuracy: 0.9476 - val_loss: 0.0829 - val_accuracy: 0.9719\n",
      "Epoch 106/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1560 - accuracy: 0.9477 - val_loss: 0.0838 - val_accuracy: 0.9746\n",
      "Epoch 107/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1485 - accuracy: 0.9473 - val_loss: 0.0716 - val_accuracy: 0.9811\n",
      "Epoch 108/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1492 - accuracy: 0.9472 - val_loss: 0.0630 - val_accuracy: 0.9816\n",
      "Epoch 109/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1526 - accuracy: 0.9470 - val_loss: 0.0667 - val_accuracy: 0.9762\n",
      "Epoch 110/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1671 - accuracy: 0.9442 - val_loss: 0.0950 - val_accuracy: 0.9719\n",
      "Epoch 111/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1635 - accuracy: 0.9443 - val_loss: 0.0720 - val_accuracy: 0.9773\n",
      "Epoch 112/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1544 - accuracy: 0.9469 - val_loss: 0.0707 - val_accuracy: 0.9789\n",
      "Epoch 113/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1466 - accuracy: 0.9515 - val_loss: 0.0767 - val_accuracy: 0.9751\n",
      "Epoch 114/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1488 - accuracy: 0.9479 - val_loss: 0.0659 - val_accuracy: 0.9800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1620 - accuracy: 0.9458 - val_loss: 0.0752 - val_accuracy: 0.9784\n",
      "Epoch 116/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1618 - accuracy: 0.9434 - val_loss: 0.0683 - val_accuracy: 0.9811\n",
      "Epoch 117/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1570 - accuracy: 0.9450 - val_loss: 0.0742 - val_accuracy: 0.9768\n",
      "Epoch 118/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1507 - accuracy: 0.9457 - val_loss: 0.0776 - val_accuracy: 0.9746\n",
      "Epoch 119/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1501 - accuracy: 0.9499 - val_loss: 0.0671 - val_accuracy: 0.9789\n",
      "Epoch 120/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1605 - accuracy: 0.9465 - val_loss: 0.0756 - val_accuracy: 0.9762\n",
      "Epoch 121/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1549 - accuracy: 0.9465 - val_loss: 0.0684 - val_accuracy: 0.9757\n",
      "Epoch 122/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1643 - accuracy: 0.9439 - val_loss: 0.0694 - val_accuracy: 0.9773\n",
      "Epoch 123/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1612 - accuracy: 0.9437 - val_loss: 0.0752 - val_accuracy: 0.9757\n",
      "Epoch 124/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1558 - accuracy: 0.9461 - val_loss: 0.0790 - val_accuracy: 0.9768\n",
      "Epoch 125/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1522 - accuracy: 0.9473 - val_loss: 0.0759 - val_accuracy: 0.9751\n",
      "Epoch 126/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1531 - accuracy: 0.9485 - val_loss: 0.0784 - val_accuracy: 0.9751\n",
      "Epoch 127/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1497 - accuracy: 0.9476 - val_loss: 0.0641 - val_accuracy: 0.9806\n",
      "Epoch 128/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1448 - accuracy: 0.9479 - val_loss: 0.0777 - val_accuracy: 0.9746\n",
      "Epoch 129/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1528 - accuracy: 0.9498 - val_loss: 0.0802 - val_accuracy: 0.9768\n",
      "Epoch 130/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1545 - accuracy: 0.9461 - val_loss: 0.0787 - val_accuracy: 0.9800\n",
      "Epoch 131/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1554 - accuracy: 0.9472 - val_loss: 0.0683 - val_accuracy: 0.9789\n",
      "Epoch 132/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1466 - accuracy: 0.9507 - val_loss: 0.0753 - val_accuracy: 0.9778\n",
      "Epoch 133/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1497 - accuracy: 0.9516 - val_loss: 0.0766 - val_accuracy: 0.9746\n",
      "Epoch 134/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1571 - accuracy: 0.9446 - val_loss: 0.0656 - val_accuracy: 0.9795\n",
      "Epoch 135/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1496 - accuracy: 0.9496 - val_loss: 0.0723 - val_accuracy: 0.9806\n",
      "Epoch 136/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1548 - accuracy: 0.9461 - val_loss: 0.0825 - val_accuracy: 0.9789\n",
      "Epoch 137/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1432 - accuracy: 0.9485 - val_loss: 0.0729 - val_accuracy: 0.9800\n",
      "Epoch 138/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1462 - accuracy: 0.9516 - val_loss: 0.0651 - val_accuracy: 0.9816\n",
      "Epoch 139/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1421 - accuracy: 0.9534 - val_loss: 0.0677 - val_accuracy: 0.9811\n",
      "Epoch 140/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1457 - accuracy: 0.9508 - val_loss: 0.0798 - val_accuracy: 0.9795\n",
      "Epoch 141/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1479 - accuracy: 0.9487 - val_loss: 0.0728 - val_accuracy: 0.9795\n",
      "Epoch 142/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1518 - accuracy: 0.9487 - val_loss: 0.0941 - val_accuracy: 0.9762\n",
      "Epoch 143/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1436 - accuracy: 0.9512 - val_loss: 0.0792 - val_accuracy: 0.9762\n",
      "Epoch 144/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1364 - accuracy: 0.9546 - val_loss: 0.0820 - val_accuracy: 0.9751\n",
      "Epoch 145/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1451 - accuracy: 0.9487 - val_loss: 0.0736 - val_accuracy: 0.9800\n",
      "Epoch 146/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1460 - accuracy: 0.9510 - val_loss: 0.0826 - val_accuracy: 0.9795\n",
      "Epoch 147/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1429 - accuracy: 0.9492 - val_loss: 0.1072 - val_accuracy: 0.9703\n",
      "Epoch 148/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1383 - accuracy: 0.9527 - val_loss: 0.0729 - val_accuracy: 0.9806\n",
      "Epoch 149/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1418 - accuracy: 0.9537 - val_loss: 0.0717 - val_accuracy: 0.9768\n",
      "Epoch 150/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1499 - accuracy: 0.9495 - val_loss: 0.0699 - val_accuracy: 0.9757\n",
      "Epoch 151/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1446 - accuracy: 0.9522 - val_loss: 0.0672 - val_accuracy: 0.9795\n",
      "Epoch 152/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1432 - accuracy: 0.9498 - val_loss: 0.0773 - val_accuracy: 0.9773\n",
      "Epoch 153/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1251 - accuracy: 0.9553 - val_loss: 0.0680 - val_accuracy: 0.9816\n",
      "Epoch 154/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1465 - accuracy: 0.9508 - val_loss: 0.0644 - val_accuracy: 0.9806\n",
      "Epoch 155/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1485 - accuracy: 0.9491 - val_loss: 0.0713 - val_accuracy: 0.9816\n",
      "Epoch 156/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1413 - accuracy: 0.9512 - val_loss: 0.0700 - val_accuracy: 0.9795\n",
      "Epoch 157/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1383 - accuracy: 0.9519 - val_loss: 0.0674 - val_accuracy: 0.9795\n",
      "Epoch 158/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1365 - accuracy: 0.9519 - val_loss: 0.0582 - val_accuracy: 0.9827\n",
      "Epoch 159/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1370 - accuracy: 0.9550 - val_loss: 0.0587 - val_accuracy: 0.9811\n",
      "Epoch 160/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1381 - accuracy: 0.9526 - val_loss: 0.0668 - val_accuracy: 0.9800\n",
      "Epoch 161/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1438 - accuracy: 0.9514 - val_loss: 0.0855 - val_accuracy: 0.9735\n",
      "Epoch 162/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1459 - accuracy: 0.9512 - val_loss: 0.0825 - val_accuracy: 0.9735\n",
      "Epoch 163/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1413 - accuracy: 0.9514 - val_loss: 0.0736 - val_accuracy: 0.9795\n",
      "Epoch 164/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1292 - accuracy: 0.9570 - val_loss: 0.0876 - val_accuracy: 0.9692\n",
      "Epoch 165/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1434 - accuracy: 0.9515 - val_loss: 0.0685 - val_accuracy: 0.9827\n",
      "Epoch 166/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1502 - accuracy: 0.9493 - val_loss: 0.0768 - val_accuracy: 0.9784\n",
      "Epoch 167/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1417 - accuracy: 0.9537 - val_loss: 0.0658 - val_accuracy: 0.9800\n",
      "Epoch 168/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1521 - accuracy: 0.9498 - val_loss: 0.0794 - val_accuracy: 0.9735\n",
      "Epoch 169/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1406 - accuracy: 0.9523 - val_loss: 0.0761 - val_accuracy: 0.9768\n",
      "Epoch 170/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1344 - accuracy: 0.9556 - val_loss: 0.0847 - val_accuracy: 0.9741\n",
      "Epoch 171/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1529 - accuracy: 0.9464 - val_loss: 0.0690 - val_accuracy: 0.9773\n",
      "Epoch 172/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1349 - accuracy: 0.9538 - val_loss: 0.0644 - val_accuracy: 0.9789\n",
      "Epoch 173/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1375 - accuracy: 0.9539 - val_loss: 0.0725 - val_accuracy: 0.9800\n",
      "Epoch 174/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1480 - accuracy: 0.9499 - val_loss: 0.0714 - val_accuracy: 0.9816\n",
      "Epoch 175/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1341 - accuracy: 0.9537 - val_loss: 0.0720 - val_accuracy: 0.9800\n",
      "Epoch 176/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1349 - accuracy: 0.9515 - val_loss: 0.0830 - val_accuracy: 0.9762\n",
      "Epoch 177/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1320 - accuracy: 0.9542 - val_loss: 0.0707 - val_accuracy: 0.9789\n",
      "Epoch 178/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1429 - accuracy: 0.9506 - val_loss: 0.0648 - val_accuracy: 0.9833\n",
      "Epoch 179/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1308 - accuracy: 0.9550 - val_loss: 0.0697 - val_accuracy: 0.9795\n",
      "Epoch 180/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1421 - accuracy: 0.9503 - val_loss: 0.0662 - val_accuracy: 0.9806\n",
      "Epoch 181/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1477 - accuracy: 0.9499 - val_loss: 0.0767 - val_accuracy: 0.9795\n",
      "Epoch 182/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1390 - accuracy: 0.9533 - val_loss: 0.0760 - val_accuracy: 0.9762\n",
      "Epoch 183/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1417 - accuracy: 0.9539 - val_loss: 0.0574 - val_accuracy: 0.9816\n",
      "Epoch 184/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1351 - accuracy: 0.9529 - val_loss: 0.0624 - val_accuracy: 0.9833\n",
      "Epoch 185/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1365 - accuracy: 0.9543 - val_loss: 0.0609 - val_accuracy: 0.9822\n",
      "Epoch 186/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1345 - accuracy: 0.9535 - val_loss: 0.0577 - val_accuracy: 0.9838\n",
      "Epoch 187/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1388 - accuracy: 0.9530 - val_loss: 0.0591 - val_accuracy: 0.9822\n",
      "Epoch 188/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1337 - accuracy: 0.9552 - val_loss: 0.0666 - val_accuracy: 0.9806\n",
      "Epoch 189/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1308 - accuracy: 0.9557 - val_loss: 0.0827 - val_accuracy: 0.9714\n",
      "Epoch 190/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1345 - accuracy: 0.9531 - val_loss: 0.0588 - val_accuracy: 0.9827\n",
      "Epoch 191/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1352 - accuracy: 0.9558 - val_loss: 0.0639 - val_accuracy: 0.9816\n",
      "Epoch 192/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1333 - accuracy: 0.9545 - val_loss: 0.0558 - val_accuracy: 0.9838\n",
      "Epoch 193/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1417 - accuracy: 0.9533 - val_loss: 0.0588 - val_accuracy: 0.9795\n",
      "Epoch 194/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1291 - accuracy: 0.9565 - val_loss: 0.0549 - val_accuracy: 0.9833\n",
      "Epoch 195/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1310 - accuracy: 0.9549 - val_loss: 0.0637 - val_accuracy: 0.9789\n",
      "Epoch 196/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1359 - accuracy: 0.9518 - val_loss: 0.0639 - val_accuracy: 0.9816\n",
      "Epoch 197/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1280 - accuracy: 0.9566 - val_loss: 0.0581 - val_accuracy: 0.9838\n",
      "Epoch 198/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1353 - accuracy: 0.9560 - val_loss: 0.0770 - val_accuracy: 0.9757\n",
      "Epoch 199/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1504 - accuracy: 0.9514 - val_loss: 0.0703 - val_accuracy: 0.9762\n",
      "Epoch 200/200\n",
      "463/463 [==============================] - 1s 3ms/step - loss: 0.1453 - accuracy: 0.9534 - val_loss: 0.0546 - val_accuracy: 0.9843\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "his=model.fit(X_train, y_train, epochs=200, batch_size=16, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3b5a364a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph section\n",
    "def smooth_curve(points, factor=0.6):\n",
    "    smoothed = []\n",
    "    for point in points:\n",
    "        if smoothed:\n",
    "            previous = smoothed[-1]\n",
    "            smoothed.append(previous * factor + point * (1 - factor))\n",
    "        else:\n",
    "            smoothed.append(point)\n",
    "    return smoothed\n",
    "\n",
    "def plot_compare(history, steps=-1):\n",
    "    if steps < 0:\n",
    "        steps = len(history.history['accuracy'])\n",
    "    train_acc = smooth_curve(history.history['accuracy'][:steps])\n",
    "    val_acc = smooth_curve(history.history['val_accuracy'][:steps])\n",
    "    train_loss = smooth_curve(history.history['loss'][:steps])\n",
    "    val_loss = smooth_curve(history.history['val_loss'][:steps])\n",
    "    \n",
    "    epochs = range(len(train_acc))\n",
    "    \n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.grid()\n",
    "    plt.plot(epochs,train_loss,'r', label='Train Loss')\n",
    "    plt.plot(epochs,val_loss,'b', label='Val Loss')\n",
    "    #plt.xticks(range(0, len(loss), 5))\n",
    "    #plt.xlim(0, len(loss))\n",
    "    plt.ylabel('Loss',fontsize=12)\n",
    "    plt.xlabel('Number of epochs')\n",
    "    plt.title('Train Loss: %.3f, Val Loss: %.3f' % (train_loss[-1], val_loss[-1]), fontsize=12)\n",
    "    plt.legend()\n",
    "    #plt.savefig(path+\"_Loss.png\",transparent=False,bbox_inches='tight')\n",
    "    \n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.grid()\n",
    "    plt.plot(epochs,train_acc,'r',label='Train Acc')\n",
    "    plt.plot(epochs,val_acc,'b', label='Val Acc')\n",
    "    #plt.xticks(range(0, len(acc), 5))\n",
    "    #plt.xlim(0, len(acc))\n",
    "    plt.ylabel('Accuracy',fontsize=12)\n",
    "    plt.xlabel('Number of epochs')\n",
    "    plt.title('Train Accuracy: %.3f, Val Accuracy: %.3f' % (train_acc[-1], val_acc[-1]), fontsize=12)\n",
    "    plt.legend()\n",
    "    #plt.savefig(path+\"_Accuracy.png\",transparent=False,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "424cd92e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_compare(history=his)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a5cc4803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0565 - accuracy: 0.9831\n",
      "Test accuracy: 0.983146071434021\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test data\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3e96bc59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73/73 [==============================] - 0s 906us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       315\n",
      "           1       0.97      0.99      0.98       483\n",
      "           2       1.00      0.99      0.99       502\n",
      "           3       1.00      0.98      0.99       512\n",
      "           4       0.96      0.98      0.97       502\n",
      "\n",
      "    accuracy                           0.98      2314\n",
      "   macro avg       0.98      0.98      0.98      2314\n",
      "weighted avg       0.98      0.98      0.98      2314\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Assuming you have already trained your neural network model and obtained the predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Convert the predicted probabilities to class labels\n",
    "y_pred_labels = label_encoder.inverse_transform(y_pred.argmax(axis=1))\n",
    "\n",
    "# Convert the true labels back from one-hot encoded format\n",
    "y_true_labels = label_encoder.inverse_transform(y_test.argmax(axis=1))\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_true_labels, y_pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1987fe73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73/73 [==============================] - 0s 840us/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "multilabel-indicator format is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [26]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m y_pred_prob_positive \u001b[38;5;241m=\u001b[39m y_pred_prob[:, \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Compute the false positive rate, true positive rate, and thresholds\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m fpr, tpr, thresholds \u001b[38;5;241m=\u001b[39m \u001b[43mroc_curve\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred_prob_positive\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Compute the area under the ROC curve (AUC)\u001b[39;00m\n\u001b[1;32m     15\u001b[0m roc_auc \u001b[38;5;241m=\u001b[39m auc(fpr, tpr)\n",
      "File \u001b[0;32m~/.conda/envs/multimodular/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:979\u001b[0m, in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mroc_curve\u001b[39m(\n\u001b[1;32m    891\u001b[0m     y_true, y_score, \u001b[38;5;241m*\u001b[39m, pos_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, drop_intermediate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    892\u001b[0m ):\n\u001b[1;32m    893\u001b[0m     \u001b[38;5;124;03m\"\"\"Compute Receiver operating characteristic (ROC).\u001b[39;00m\n\u001b[1;32m    894\u001b[0m \n\u001b[1;32m    895\u001b[0m \u001b[38;5;124;03m    Note: this implementation is restricted to the binary classification task.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    977\u001b[0m \n\u001b[1;32m    978\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 979\u001b[0m     fps, tps, thresholds \u001b[38;5;241m=\u001b[39m \u001b[43m_binary_clf_curve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    983\u001b[0m     \u001b[38;5;66;03m# Attempt to drop thresholds corresponding to points in between and\u001b[39;00m\n\u001b[1;32m    984\u001b[0m     \u001b[38;5;66;03m# collinear with other points. These are always suboptimal and do not\u001b[39;00m\n\u001b[1;32m    985\u001b[0m     \u001b[38;5;66;03m# appear on a plotted ROC curve (and thus do not affect the AUC).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    990\u001b[0m     \u001b[38;5;66;03m# but does not drop more complicated cases like fps = [1, 3, 7],\u001b[39;00m\n\u001b[1;32m    991\u001b[0m     \u001b[38;5;66;03m# tps = [1, 2, 4]; there is no harm in keeping too many thresholds.\u001b[39;00m\n\u001b[1;32m    992\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m drop_intermediate \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(fps) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[0;32m~/.conda/envs/multimodular/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:738\u001b[0m, in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    736\u001b[0m y_type \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    737\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m pos_label \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)):\n\u001b[0;32m--> 738\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m format is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(y_type))\n\u001b[1;32m    740\u001b[0m check_consistent_length(y_true, y_score, sample_weight)\n\u001b[1;32m    741\u001b[0m y_true \u001b[38;5;241m=\u001b[39m column_or_1d(y_true)\n",
      "\u001b[0;31mValueError\u001b[0m: multilabel-indicator format is not supported"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Assuming you have already trained your binary classification model and obtained the predicted probabilities\n",
    "y_pred_prob = model.predict(X_test)\n",
    "\n",
    "# Extract the probabilities for the positive class (assuming binary classification)\n",
    "y_pred_prob_positive = y_pred_prob[:, 0]\n",
    "\n",
    "# Compute the false positive rate, true positive rate, and thresholds\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob_positive)\n",
    "\n",
    "# Compute the area under the ROC curve (AUC)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (AUC = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875778c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
